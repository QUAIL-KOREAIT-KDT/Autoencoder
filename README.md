# **ğŸ¯ ì˜¤í† ì¸ì½”ë” ê¸°ë°˜ Animal Image Retrieval(CBIR) êµ¬í˜„**

## **ê²°ë¡  ë° í”„ë¡œì íŠ¸ ë¶„ì„**

### 1. í”„ë¡œì íŠ¸ ìš”ì•½
> ë³¸ í”„ë¡œì íŠ¸ëŠ” Convolutional Autoencoder(CAE)ë¥¼ í™œìš©í•˜ì—¬ ë™ë¬¼ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì— ëŒ€í•œ ìœ ì‚¬ ì´ë¯¸ì§€ ê²€ìƒ‰(CBIR) ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ì˜€ìŠµë‹ˆë‹¤.

- ëª¨ë¸ êµ¬ì¡°: Encoder(íŠ¹ì§• ì¶”ì¶œ)ì™€ Decoder(ì´ë¯¸ì§€ ë³µì›)ë¡œ êµ¬ì„±ëœ CNN ê¸°ë°˜ ì˜¤í† ì¸ì½”ë”.

```python
class ConvAutoencoder(nn.Module):
    def __init__(self):
        super(ConvAutoencoder, self).__init__()

        # [Encoder] : 128x128 -> 64x64 -> 32x32 -> 16x16 (ì••ì¶•)
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 16, 3, stride=2, padding=1), # (3, 128, 128) -> (16, 64, 64)
            nn.ReLU(),
            nn.Conv2d(16, 32, 3, stride=2, padding=1), # (16, 64, 64) -> (32, 32, 32)
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, stride=2, padding=1), # (32, 32, 32) -> (64, 16, 16)
            nn.ReLU()
        )

        # [Decoder] : 16x16 -> 32x32 -> 64x64 -> 128x128 (ë³µì›)
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # (64, 16, 16) -> (32, 32, 32)
            nn.ReLU(),
            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), # (32, 32, 32) -> (16, 64, 64)
            nn.ReLU(),
            nn.ConvTranspose2d(16, 3, 3, stride=2, padding=1, output_padding=1), # (16, 64, 64) -> (3, 128, 128)
            nn.Sigmoid() # í”½ì…€ ê°’ 0~1 ì‚¬ì´ë¡œ ë³µì›
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded
    
    # íŠ¹ì§• ì¶”ì¶œì„ ìœ„í•œ í¸ì˜ í•¨ìˆ˜ (í•™ìŠµ í›„ ì‚¬ìš©)
    def get_latent_feature(self, x):
        with torch.no_grad():
            encoded = self.encoder(x)
            # (Batch, 64, 16, 16) -> (Batch, 64*16*16) = (Batch, 16384) í˜•íƒœë¡œ í‰íƒ„í™”
            flattened = encoded.view(encoded.size(0), -1)
        return flattened
```

- í•µì‹¬ ì›ë¦¬: ì´ë¯¸ì§€ë¥¼ í”½ì…€ ë‹¨ìœ„ë¡œ ë¹„êµí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, í•™ìŠµëœ ëª¨ë¸ì´ ì¶”ì¶œí•œ Latent Feature(ì ì¬ íŠ¹ì§•) ë²¡í„° ê°„ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬(Euclidean Distance)ë¥¼ ê³„ì‚°í•˜ì—¬ ìœ ì‚¬ë„ë¥¼ íŒë‹¨í•¨.

```python
from sklearn.neighbors import NearestNeighbors

# 1. ê²€ìƒ‰ ì—”ì§„ ì„¤ì • (ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê¸°ì¤€)
# n_neighbors=6 ì¸ ì´ìœ : ìê¸° ìì‹ (ê±°ë¦¬ 0)ì´ 1ë“±ìœ¼ë¡œ ë‚˜ì˜¤ê¸° ë•Œë¬¸ì—, ìê¸° ìì‹  í¬í•¨ ìƒìœ„ 6ê°œë¥¼ ë½‘ìŠµë‹ˆë‹¤.
knn = NearestNeighbors(n_neighbors=6, metric='euclidean')
knn.fit(features_db)

def search_and_visualize(query_idx):
    """
    ë°ì´í„°ì…‹ ë‚´ì˜ íŠ¹ì • ì¸ë±ìŠ¤(query_idx) ì´ë¯¸ì§€ë¥¼ Queryë¡œ ì‚¬ìš©í•˜ì—¬
    ê°€ì¥ ìœ ì‚¬í•œ ì´ë¯¸ì§€ 5ì¥ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.
    """

    # Query ì´ë¯¸ì§€ì˜ íŠ¹ì§• ë²¡í„° ê°€ì ¸ì˜¤ê¸°
    query_feature = features_db[query_idx].reshape(1, -1)

    # ê²€ìƒ‰ ì‹¤í–‰ (ê±°ë¦¬ì™€ ì¸ë±ìŠ¤ ë°˜í™˜)
    distances, indices = knn.kneighbors(query_feature)

    # ê²°ê³¼ ì‹œê°í™”
    plt.figure(figsize=(15, 5))

    # ê²°ê³¼ ì¶œë ¥ (ì²« ë²ˆì§¸ëŠ” Query ì´ë¯¸ì§€, ê·¸ ë’¤ë¡œ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë“¤)
    for i in range(6):
        found_idx = indices[0][i]
        dist = distances[0][i]

        # ì´ë¯¸ì§€ ë¡œë“œ
        img_path = image_paths[found_idx]
        img = Image.open(img_path).convert("RGB")

        ax = plt.subplot(1, 6, i + 1)

        if i == 0:
            ax.set_title("Query Image", color='red', fontsize=14, fontweight='bold')
            # í…Œë‘ë¦¬ ê°•ì¡° (Query)
            for spine in ax.spines.values():
                spine.set_edgecolor('red')
                spine.set_linewidth(3)
        else:
            ax.set_title(f"Rank {i}\nDist: {dist:.4f}", fontsize=10)
            
        plt.imshow(img)
        plt.axis('off')
    
    plt.show()

```


### 2. í•™ìŠµ ê²°ê³¼ ë¶„ì„
- Loss ë³€í™”: í•™ìŠµì´ ì§„í–‰ë¨ì— ë”°ë¼ MSE Lossê°€ 0.0039 ìˆ˜ì¤€ìœ¼ë¡œ ìˆ˜ë ´í•˜ì˜€ìœ¼ë©°, ì´ëŠ” ëª¨ë¸ì´ ì›ë³¸ ì´ë¯¸ì§€ì˜ ì£¼ìš” íŠ¹ì§•ì„ ì†ì‹¤ ì—†ì´ ì˜ ì••ì¶•í•˜ê³  ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
<img src="./AutoencoderIMG/AutoencoderLossGraph.png">


- ê²€ìƒ‰ ì„±ëŠ¥: Query ì´ë¯¸ì§€(ì˜ˆ: í˜¸ë‘ì´)ë¥¼ ì…ë ¥í–ˆì„ ë•Œ, ê°™ì€ ì¢…ì˜ ë™ë¬¼ì´ë‚˜ ìœ ì‚¬í•œ ìƒ‰ê°/ìì„¸ë¥¼ ê°€ì§„ ì´ë¯¸ì§€ë“¤ì´ Top-5 ê²°ê³¼ë¡œ ë„ì¶œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ë™ë¬¼ì˜ [í˜•íƒœ, ìƒ‰ìƒ, ë°°ê²½] ë“±ì˜ íŠ¹ì§•ì„ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí–ˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
<img src="./AutoencoderIMG/AutoencoderQueryImage.png">
<img src="./AutoencoderIMG/AutoQueryImage_2.png">
<img src="./AutoencoderIMG/AutoQueryImage_3.png">

### 3. í•œê³„ì  ë° ê°œì„  ë°©ì•ˆ (Future Work)
- íë¦¿í•œ ë³µì›: MSE Lossì˜ íŠ¹ì„±ìƒ ë³µì›ëœ ì´ë¯¸ì§€ê°€ ë‹¤ì†Œ íë¦¿(Blurry)í•´ì§€ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ GAN(Generative Adversarial Networks) ê¸°ë°˜ì˜ í•™ìŠµì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- ë³µì¡í•œ ë°°ê²½: ë™ë¬¼ì´ ì‘ê²Œ ë‚˜ì˜¤ê±°ë‚˜ ë°°ê²½ì´ ë³µì¡í•œ ê²½ìš° ê²€ìƒ‰ ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ê°ì²´ íƒì§€(Object Detection) ì „ì²˜ë¦¬ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ResNetê³¼ ê°™ì€ ë” ê¹Šì€ ëª¨ë¸ì„ Encoderë¡œ ì‚¬ìš©í•˜ëŠ” ì „ì´ í•™ìŠµ(Transfer Learning)ì„ ì ìš©í•˜ë©´ ì„±ëŠ¥ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
